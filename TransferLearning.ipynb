{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyP1zwq467jl97M85yOdLt2W"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Setup our environment\n",
        "\n",
        "Import neccessary code, requirements, etc."
      ],
      "metadata": {
        "id": "ONJtmvUQ1Vlx"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yeEyjFvFx9to"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torchvision\n",
        "\n",
        "print(torchvision.__version__)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "import torchvision\n",
        "\n",
        "from torch import nn\n",
        "from torchvision import transforms\n",
        "\n",
        "# Try to get torchinfo, install it if it doesn't work\n",
        "try:\n",
        "    from torchinfo import summary\n",
        "except:\n",
        "    print(\"[INFO] Couldn't find torchinfo... installing it.\")\n",
        "    !pip install -q torchinfo\n",
        "    from torchinfo import summary\n",
        "\n",
        "# Try to import the going_modular directory, download it from GitHub if it doesn't work\n",
        "try:\n",
        "    from going_modular.going_modular import data_setup, engine\n",
        "except:\n",
        "    # Get the going_modular scripts\n",
        "    print(\"[INFO] Couldn't find going_modular scripts... downloading them from GitHub.\")\n",
        "    !git clone https://github.com/mrdbourke/pytorch-deep-learning\n",
        "    !mv pytorch-deep-learning/going_modular .\n",
        "    !rm -rf pytorch-deep-learning\n",
        "    from going_modular.going_modular import data_setup, engine"
      ],
      "metadata": {
        "id": "AmSFa4WC2Wk_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
      ],
      "metadata": {
        "id": "dbdcj3zL4AfS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Get our data"
      ],
      "metadata": {
        "id": "goNjOrlJQ8c7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import zipfile\n",
        "\n",
        "from pathlib import Path\n",
        "\n",
        "data_path = Path(\"data\")\n",
        "image_path = data_path / \"pizza_steak_sushi\"\n",
        "\n",
        "import requests\n",
        "def create_data(url):\n",
        "  \"\"\"\n",
        "  Creates data for a computer vision model given a URL that requests can acces\n",
        "  \"\"\"\n",
        "  data_path = Path(\"data\")\n",
        "  image_path = data_path / \"pizza_steak_sushi\"\n",
        "\n",
        "  if image_path.is_dir():\n",
        "    print(f\"{image_path} directory exists, skipping re-download\")\n",
        "  else:\n",
        "    print(f\"Did not find {image_path}, making new path\")\n",
        "    image_path.mkdir(parents=True,\n",
        "                    exist_ok=True)\n",
        "\n",
        "    with open(data_path / \"pizza_steak_sushi.zip\", \"wb\") as f:\n",
        "      request = requests.get(url)\n",
        "      f.write(request.content)\n",
        "\n",
        "    with zipfile.ZipFile(data_path / \"pizza_steak_sushi.zip\", \"r\") as zip_ref:\n",
        "      print(\"Unzipping our data..\")\n",
        "      zip_ref.extractall(image_path)\n",
        "\n",
        "    os.remove(data_path / \"pizza_steak_sushi.zip\")\n",
        "\n",
        "create_data(\"https://github.com/mrdbourke/pytorch-deep-learning/raw/main/data/pizza_steak_sushi.zip\")"
      ],
      "metadata": {
        "id": "ZgsSUq3Q4zv2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dir = image_path / \"train\"\n",
        "test_dir = image_path / \"test\""
      ],
      "metadata": {
        "id": "nJ_LMpl0SZA7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dir"
      ],
      "metadata": {
        "id": "PUfYSkZpSwEO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create our `Datasets` and `DataLoaders`\n",
        "\n",
        "We can use our `data_setup.py`, specifically the `create_dataloaders.py` function in going_modular\n",
        "\n",
        "\n",
        "We also need to **transform** the data we get, where there are manual and automatic transforms. We need to be careful if we take another model as we need to transform our data into the same way the model was trained.\n",
        "\n",
        "\n",
        "We'll manually create transforms for the `torchvision.models`"
      ],
      "metadata": {
        "id": "NODt2_mMTFJp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Create a transform manually"
      ],
      "metadata": {
        "id": "35uuxpI2veqh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from going_modular.going_modular import data_setup\n",
        "\n",
        "normalize = transforms.Normalize(mean=[.485, .456, .406],\n",
        "                                 std=[.229,.224,.225])\n",
        "\n",
        "manual_transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    normalize\n",
        "])\n",
        "\n",
        "manual_transform\n"
      ],
      "metadata": {
        "id": "IUvC0eBeSyH0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataloader, test_dataloader, class_names = data_setup.create_dataloaders(train_dir,\n",
        "                                                                               test_dir,\n",
        "                                                                               manual_transform,\n",
        "                                                                               32)"
      ],
      "metadata": {
        "id": "S0ny5NuVW9ES"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class_names"
      ],
      "metadata": {
        "id": "Cv_RARtZXHFw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "img, label = next(iter(train_dataloader))"
      ],
      "metadata": {
        "id": "qYzTfdJOXIKg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ncIVac5tXKAg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Create a transform automatically"
      ],
      "metadata": {
        "id": "LVjTj6mpXo2a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "weights = torchvision.models.EfficientNet_B0_Weights.DEFAULT"
      ],
      "metadata": {
        "id": "cnHgUiQDXOkc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "weights"
      ],
      "metadata": {
        "id": "yx1BzzrHaVv8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "auto_transforms = weights.transforms"
      ],
      "metadata": {
        "id": "IslHy2UWaZEw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "auto_transforms"
      ],
      "metadata": {
        "id": "lvQLtwDyarVf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataloader, test_dataloader, class_names = data_setup.create_dataloaders(train_dir,\n",
        "                                                                               test_dir,\n",
        "                                                                               auto_transforms(),\n",
        "                                                                               32)"
      ],
      "metadata": {
        "id": "qNoj4G7_asW1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(train_dataloader), len(test_dataloader)"
      ],
      "metadata": {
        "id": "IWB7QNXgbFTl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Getting a pre-trained model based on the data we want to train on\n",
        "\n",
        "We can use:\n",
        "* PyTorch Domain libraries\n",
        "* HuggingFace Hub\n",
        "* Libraries like `timm`\n",
        "\n",
        "Now, we need to choose a model to use. This is done through tons of experimenting on which model best suits our data.\n",
        "\n",
        "Factors like-\n",
        "* Speed\n",
        "* Size\n",
        "* Computational memory/usage\n",
        "\n",
        "-can all change what model we choose.\n",
        "\n",
        "Since we want to run this app on a mobile phone, EffNetB0 is a great option as we don't use too much memory but we need high performance/accuracy."
      ],
      "metadata": {
        "id": "0iJX2zXfkkOb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Setup our pretained model with an instance:"
      ],
      "metadata": {
        "id": "sOBYCy0GvWYa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "weights = torchvision.models.EfficientNet_B0_Weights.DEFAULT\n",
        "model = torchvision.models.efficientnet_b0(weights=weights)"
      ],
      "metadata": {
        "id": "VJ1uaolebLPD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.avgpool"
      ],
      "metadata": {
        "id": "Tz4DpY__wQf3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.classifier"
      ],
      "metadata": {
        "id": "vGWFX6fuxDfX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Since we have a small amount of custom data, we want to use **feature extraction** to make our new model"
      ],
      "metadata": {
        "id": "b0pz7TGE0LAE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Getting a summary of our model"
      ],
      "metadata": {
        "id": "JXCrhk2_0XdO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "summary(model=model,\n",
        "        input_size=(1, 3, 224, 224),\n",
        "        col_names=[\"input_size\", \"output_size\", \"num_params\", \"trainable\"],\n",
        "        col_width=20,\n",
        "        row_settings=[\"var_names\"])"
      ],
      "metadata": {
        "id": "l0C5dFXL0U0X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Freeze base model, change output layer to help suit our dataset\n",
        "\n",
        "Using feature extraction, we need to freeze our base layers of the pretained model and update the output layers to suit the problem"
      ],
      "metadata": {
        "id": "fUd7Ekmusf3n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for param in model.features.parameters():\n",
        "  param.requires_grad = False"
      ],
      "metadata": {
        "id": "7JRHyA7qxFcW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "summary(model=model,\n",
        "        input_size=(1, 3, 224, 224),\n",
        "        col_names=[\"input_size\", \"output_size\", \"num_params\", \"trainable\"],\n",
        "        col_width=20,\n",
        "        row_settings=[\"var_names\"])\n"
      ],
      "metadata": {
        "id": "sQ8BzOdptTMl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, we update our classifier"
      ],
      "metadata": {
        "id": "KiEwuNd9towK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.classifier"
      ],
      "metadata": {
        "id": "GPOt_xmAtXP5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(42)\n",
        "torch.cuda.manual_seed(42)\n",
        "\n",
        "from torch import nn\n",
        "model.classifier = nn.Sequential(\n",
        "    nn.Dropout(p=0.2,inplace=True),\n",
        "    nn.Linear(in_features=1280, out_features=len(class_names))\n",
        ")\n",
        "\n",
        "model.classifier"
      ],
      "metadata": {
        "id": "n3r2uwJDtrUY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "summary(model=model,\n",
        "        input_size=(1, 3, 224, 224),\n",
        "        col_names=[\"input_size\", \"output_size\", \"num_params\", \"trainable\"],\n",
        "        col_width=20,\n",
        "        row_settings=[\"var_names\"])"
      ],
      "metadata": {
        "id": "Q735FLxbvHLI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Train our new model"
      ],
      "metadata": {
        "id": "YK0jeBgsv0Pr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "loss_fn = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(),\n",
        "                             lr=.001)"
      ],
      "metadata": {
        "id": "9vUAZqc2vL5D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from going_modular.going_modular import engine\n",
        "from timeit import default_timer as timer\n",
        "\n",
        "torch.manual_seed(42)\n",
        "torch.cuda.manual_seed(42)\n",
        "\n",
        "start_time = timer()\n",
        "\n",
        "# Setup our training\n",
        "results = engine.train(model=model,\n",
        "                       train_dataloader=train_dataloader,\n",
        "                       test_dataloader=test_dataloader,\n",
        "                       optimizer=optimizer,\n",
        "                       loss_fn=loss_fn,\n",
        "                       epochs=5,\n",
        "                       device=device)\n",
        "\n",
        "end_time = timer()\n",
        "print(f\"Training model took {end_time-start_time} seconds.\")"
      ],
      "metadata": {
        "id": "Nfy2-zd4wDw4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "results"
      ],
      "metadata": {
        "id": "CqM5SN1W2SJm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import importlib\n",
        "try:\n",
        "  from helper_functions import plot_loss_curves\n",
        "except:\n",
        "  with open(\"helper_functions.py\", \"wb\") as f:\n",
        "    import requests\n",
        "    request = requests.get(\"https://github.com/mrdbourke/pytorch-deep-learning/raw/main/helper_functions.py\")\n",
        "    f.write(request.content)\n",
        "\n",
        "import helper_functions\n",
        "\n",
        "importlib.reload(helper_functions)\n",
        "\n",
        "from helper_functions import plot_loss_curves"
      ],
      "metadata": {
        "id": "Q93BPVEbhNf1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_loss_curves(results)"
      ],
      "metadata": {
        "id": "psv03qVTg1vK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Make predictions on test data\n",
        "\n",
        "We have to format our data correctly, making sure our custom data is the same shape, same datatype, same transform, and same device"
      ],
      "metadata": {
        "id": "qMIpS833iT6H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image\n",
        "from typing import List, Tuple\n",
        "\n",
        "\n",
        "def pred_and_plot_image(model,\n",
        "                        image_path,\n",
        "                        class_names,\n",
        "                        image_size = (224, 224),\n",
        "                        transform=None,\n",
        "                        device = device):\n",
        "\n",
        "  new_image = Image.open(image_path)\n",
        "\n",
        "  if transform:\n",
        "    image_transform = transform\n",
        "  else:\n",
        "      image_transform = transforms.Compose([\n",
        "      transforms.Resize(size=(224, 224)),\n",
        "      transforms.ToTensor(),\n",
        "      transforms.Normalize(mean=[.485, .456, .406],\n",
        "                                 std=[.229,.224,.225])\n",
        "  ])\n",
        "\n",
        "  model = model.to(device)\n",
        "\n",
        "  model.eval()\n",
        "  with torch.inference_mode():\n",
        "    transformed_image = image_transform(new_image).unsqueeze(dim=0)\n",
        "\n",
        "    new_image_probs = model(transformed_image.to(device))\n",
        "  new_image_preds = torch.softmax(new_image_probs, dim=1).argmax(dim=1)\n",
        "\n",
        "  plt.figure()\n",
        "  plt.imshow(new_image)\n",
        "  plt.title(f\"Predicted: {class_names[new_image_preds]} | Prob: {torch.softmax(new_image_probs, dim=1).max():.3f}\")\n",
        "\n"
      ],
      "metadata": {
        "id": "M0d4Qe6TeMBf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "from pathlib import Path\n",
        "num_plot_images = 3\n",
        "test_image_path_list = list(Path(test_dir).glob(\"*/*.jpg\"))\n",
        "test_image_samples = random.sample(test_image_path_list,\n",
        "                                   k=num_plot_images)\n",
        "\n",
        "\n",
        "for image_path in test_image_samples:\n",
        "  pred_and_plot_image(model,\n",
        "                      image_path,\n",
        "                      class_names)"
      ],
      "metadata": {
        "id": "A25cAr0EiOqT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Making predictions on the test dataset\n",
        "try:\n",
        "  import torchmetrics\n",
        "  import mlxtend\n",
        "except:\n",
        "  !pip install torchmetrics\n",
        "  !pip install mlxtend"
      ],
      "metadata": {
        "id": "Dr8M0qatEALw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torchmetrics.classification import MulticlassConfusionMatrix\n",
        "from mlxtend.plotting import plot_confusion_matrix\n",
        "\n",
        "confmat = MulticlassConfusionMatrix(num_classes=len(class_names)).to(device)"
      ],
      "metadata": {
        "id": "rCDBk_GdM9Yc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.eval()\n",
        "with torch.inference_mode():\n",
        "  for batch, (X, y) in enumerate(test_dataloader):\n",
        "    X, y = X.to(device), y.to(device)\n",
        "    test_probs = torch.softmax(model(X), dim=1)\n",
        "    test_preds = torch.argmax(test_probs, dim=1)\n",
        "    confmat.update(test_preds, y)\n",
        "\n",
        "  fig, ax = confmat.plot()"
      ],
      "metadata": {
        "id": "rwUA-vSMNqBW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pathlib import Path\n",
        "test_data_paths = list(Path(test_dir).glob(\"*/*.jpg\"))\n",
        "test_labels = [path.parent.stem for path in test_data_paths]\n",
        "\n",
        "def pred_and_store(test_paths, model, transform, class_names):\n",
        "  test_pred_list = []\n",
        "  for path in test_paths:\n",
        "    pred_dict = {}\n",
        "\n",
        "    class_name = path.parent.stem\n",
        "    pred_dict[\"image_path\"] = path\n",
        "    pred_dict[\"class_name\"] = class_name\n",
        "    from PIL import Image\n",
        "    img = Image.open(path)\n",
        "    transformed_image = transform(img).unsqueeze(0)\n",
        "    model.eval()\n",
        "    with torch.inference_mode():\n",
        "      pred_logits = model(transformed_image.to(device))\n",
        "      pred_prob = torch.softmax(pred_logits, dim=1)\n",
        "      pred_label = torch.argmax(pred_prob, dim=1)\n",
        "      pred_class = class_names[pred_label]\n",
        "      pred_dict[\"pred_prob\"] = pred_prob.max().item()\n",
        "      pred_dict[\"pred_label\"] = pred_class\n",
        "\n",
        "      pred_dict[\"correct\"] = class_name == pred_class\n",
        "\n",
        "      test_pred_list.append(pred_dict)\n",
        "\n",
        "  return test_pred_list\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "IchGH5riPkVN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Plotting the images the model was the \"most\" wrong about (had the smallest probability for the correct class)"
      ],
      "metadata": {
        "id": "V1OToCOiSMPN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_list = pred_and_store(test_data_paths,\n",
        "               model,\n",
        "               manual_transform,\n",
        "               class_names\n",
        ")\n",
        "\n",
        "import pandas as pd\n",
        "test_pred_df = pd.DataFrame(test_list)\n",
        "worst_five = test_pred_df.sort_values(by=[\"correct\", \"pred_prob\"], ascending=[True, False]).head()\n",
        "worst_five"
      ],
      "metadata": {
        "id": "BfBKcxsWR0qq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "most_wrong_images = worst_five.image_path.tolist()\n",
        "most_wrong_images\n",
        "\n",
        "for row in worst_five.iterrows():\n",
        "  row = row[1]\n",
        "  true_label = row[1]"
      ],
      "metadata": {
        "id": "IlTYLVi3Qm3L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i, image_path in enumerate(most_wrong_images):\n",
        "  img = Image.open(image_path)\n",
        "  plt.figure(figsize = (10, 7))\n",
        "  plt.subplot(2, 3, i+1)\n",
        "  plt.axis(False)\n",
        "  plt.imshow(img)"
      ],
      "metadata": {
        "id": "iX_qhBZgX4qg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Ga0AwbbPYXLP"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}